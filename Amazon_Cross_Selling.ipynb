{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def setup_my_environment():\n",
    "    import os\n",
    "    \n",
    "def setenv(var, val):\n",
    "    os.environ[var] = val\n",
    "\n",
    "def prepend_path(var, val):\n",
    "    old_val = os.environ.get(var, '')\n",
    "    os.environ[var] = val + \":\" + old_val\n",
    "def setup_java():\n",
    "    PKG_ROOT='/ichec/packages/java/8'\n",
    "    setenv('JAVA_PATH', PKG_ROOT)\n",
    "    setenv('JAVA_HOME', PKG_ROOT)\n",
    "    prepend_path('PATH', PKG_ROOT + '/bin')\n",
    "    prepend_path('MANPATH', PKG_ROOT + '/man')\n",
    "    prepend_path('CPATH', PKG_ROOT + '/include')\n",
    "def setup_spark():\n",
    "    PKG_ROOT='/ichec/packages/spark/2.3.3/kay/spark-2.3.3'\n",
    "    setenv('SPARK_DIST_CLASSPATH', PKG_ROOT + 'spark-2.3.3-bin-kay-spark')\n",
    "    prepend_path('PATH', PKG_ROOT + PKG_ROOT + 'spark-2.3.3-bin-kay-spark/bin')\n",
    "          \n",
    "setup_java()\n",
    "setup_spark()\n",
    "setup_my_environment()\n",
    "from pyspark import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config(\"spark.executor.memory\", \"35g\") \\\n",
    "    .config(\"spark.executor.cores\",\"3\")\\\n",
    "    .config(\"spark.driver.memory\", \"100g\") \\\n",
    "    .config(\"spark.executor.instance\",\"12\")\\\n",
    "    .config('spark.sql.shuffle.partitions',\"128\")\\\n",
    "    .config(\"spark.sql.crossJoin.enabled\",\"true\")\\\n",
    "    .config(\"spark.debug.maxToStringsFields\",\"100\")\\\n",
    "    .appName(\"AmazonCrossSelling\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.json(\"/ichec/work/mucom001c/Amazon/review/All_Beauty.json\")\n",
    "df2 = spark.read.json(\"/ichec/work/mucom001c/Amazon/review/AMAZON_FASHION.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.join(df2,[\"asin\",\"image\",\"overall\",\"reviewText\",\"reviewTime\",\"reviewerID\",\"reviewerName\",\"summary\",\"unixReviewTime\",\"verified\",\"vote\"],\"full_outer\").drop(\"style\")\n",
    "df.show(5)\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "df.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n",
    "df = df.fillna({'vote':'1'})\n",
    "df = df.withColumn('verified', F.when(df.verified == 'false', 0).otherwise(1))\n",
    "df.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.select('asin','overall','reviewerID','verified','vote')\n",
    "feature_group = [\"reviewerID\",\"asin\",\"verified\"]\n",
    "df_avg =df.groupby(feature_group).agg(F.mean(\"overall\").alias(\"Average\"))\n",
    "df_count = df.groupby(feature_group).count()\n",
    "df_final = df_avg.join(df_count,feature_group)\n",
    "df_vote = df.groupby(feature_group).agg(F.sum(\"vote\").alias(\"Total_Votes\"))\n",
    "df_final = df_final.join(df_vote,feature_group)\n",
    "df_final = df_final.join(df_new,feature_group)\n",
    "df_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "revIDindexer = StringIndexer(inputCol=\"reviewerID\", outputCol=\"reviewerID_index\")\n",
    "asinindexer = StringIndexer(inputCol=\"asin\",outputCol=\"asin_index\")\n",
    "pipeline = Pipeline(stages=[asinindexer,revIDindexer])\n",
    "df_final = pipeline.fit(df_final).transform(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "unlist = udf(lambda x: round(float(list(x)[0]),3), DoubleType())\n",
    "for i in [\"reviewerID_index\",\"asin_index\",\"count\",\"Average\",\"Total_Votes\"]:\n",
    "    assembler = VectorAssembler(inputCols=[i],outputCol=i+\"_Vect\",handleInvalid = \"skip\")\n",
    "    scaler = MinMaxScaler(inputCol=i+\"_Vect\", outputCol=i+\"_Scaled\")\n",
    "    pipeline = Pipeline(stages=[assembler, scaler])\n",
    "    df_final = pipeline.fit(df_final).transform(df_final).withColumn(i+\"_Scaled\", unlist(i+\"_Scaled\")).drop(i+\"_Vect\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "vecAssembler = VectorAssembler(inputCols=[\"reviewerID_index_Scaled\",\"asin_index_Scaled\",\"count_Scaled\",\"Average_Scaled\",\"Total_Votes_Scaled\"], outputCol=\"features\",handleInvalid = \"skip\")\n",
    "new_df = vecAssembler.transform(df_final)\n",
    "new_df=new_df.drop('count','Total_Votes','reviewerID_index','asin_index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "list_k1 = []\n",
    "list_k = list(range(2,10))\n",
    "for i in list_k:\n",
    "    kmeans = KMeans(maxIter = 3).setK(i).setSeed(1)\n",
    "    model_kmeans = kmeans.fit(new_df)\n",
    "    list_k1.append(list_k)\n",
    "    wcss.append(model_kmeans.computeCost(new_df))\n",
    "    print(\"Within Set Sum of Squared Errors = \" + str(wcss))\n",
    "    print(\"Value of k = \" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(list_k, wcss,marker = 'o')\n",
    "plt.xlabel(r'Number of clusters *k*')\n",
    "plt.ylabel('Sum of squared distance')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmeans algorithm\n",
    "kmeans = KMeans(maxIter = 5).setK(5).setSeed(1).setPredictionCol(\"cluster_prediction\")\n",
    "model_kmeans = kmeans.fit(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating Silhouette distance\n",
    "evaluator_kmeans = ClusteringEvaluator().setPredictionCol(\"cluster_prediction\")\n",
    "df_predictions = model_kmeans.transform(new_df)\n",
    "silhouette_kmeans = evaluator_kmeans.evaluate(df_predictions)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette_kmeans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revID = input(\"Enter your reviewerID:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = df_predictions.filter(df_predictions['reviewerID'] == revID).select('cluster_prediction').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.createOrReplaceTempView(\"KmeansAmazonDataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = spark.sql(\"SELECT asin from KmeansAmazonDataset where Average >= 4 and cluster_prediction = '{0}'\".format(cluster.first().cluster_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting Naive Bayes\n",
    "# Creating Label\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import when\n",
    "df_final = df_final.withColumn(\n",
    "    'label',\n",
    "     when((col(\"overall\").between(4, 5)),1.0).when((col(\"overall\").between(0,3)),0.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_df,test_df)=df_final.randomSplit([0.6, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes algorithm for recommendation of products cross validation with various smoothing values.\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "vecAssembler_NB = VectorAssembler(inputCols=[\"asin_index\", \"reviewerID_index\"], outputCol=\"features\")\n",
    "nb = NaiveBayes(modelType=\"multinomial\")\n",
    "paramGrid = ParamGridBuilder().addGrid(nb.smoothing, [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]).build()\n",
    "pipeline_NB = Pipeline(stages=[vecAssembler_NB, nb])\n",
    "(training_df,test_df)=df_final.randomSplit([0.6, 0.4])\n",
    "cvEvaluator = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol= \"prediction\", metricName=\"accuracy\")\n",
    "cv = CrossValidator(estimator=pipeline_NB, estimatorParamMaps=paramGrid, evaluator=cvEvaluator,numFolds = 4)\n",
    "NB_Model = cv.fit(training_df)\n",
    "NB_Predictions = NB_Model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes without Cross-Validation\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "nb = NaiveBayes(smoothing = 0.5)\n",
    "vecAssembler_NB = VectorAssembler(inputCols=[\"asin_index\",\"reviewerID_index\"], outputCol=\"features\",handleInvalid = \"skip\")\n",
    "pipeline_NB = Pipeline(stages=[vecAssembler_NB, nb])\n",
    "model = pipeline_NB.fit(training_df)\n",
    "predictions = model.transform(test_df)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",metricName=\"accuracy\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "prediction_evaluation = predictions.select(\"prediction\", \"label\").rdd\n",
    "metrics = MulticlassMetrics(prediction_evaluation)\n",
    "print(\"*****Printing Confusion matrix***** \")\n",
    "print(metrics.confusionMatrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = predictions.filter(predictions['reviewerID']==revID).select(col(\"reviewerID\"),col(\"asin\").alias(\"item\"),col(\"label\"),col(\"overall\"),col(\"prediction\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item Recommended for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Printing first five recommendations from the list using k means and Naive Bayes\")\n",
    "df3.select('asin').distinct().show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS Method For Recommendation of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommendation using ALS method\n",
    "df_ALS = new_df.select(new_df['asin'],new_df['reviewerID'],new_df['Average'])\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n",
    "revIDindexer = StringIndexer(inputCol=\"reviewerID\", outputCol=\"reviewerID_index\")\n",
    "asinindexer = StringIndexer(inputCol=\"asin\",outputCol=\"asin_index\")\n",
    "pipeline = Pipeline(stages={asinindexer,revIDindexer})\n",
    "transformed = pipeline.fit(df_ALS).transform(df_ALS)\n",
    "(training_df,test_df)=transformed.randomSplit([0.6, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding best model for ALS method using average\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "als_avg=ALS(userCol=\"reviewerID_index\",itemCol=\"asin_index\",ratingCol=\"Average\",coldStartStrategy=\"drop\",nonnegative=True).setPredictionCol(\"ALS_prediction_avg\")\n",
    "param_grid = ParamGridBuilder()\\\n",
    "    .addGrid(als_avg.rank, [100,150])\\\n",
    "    .addGrid(als_avg.maxIter, [5])\\\n",
    "    .addGrid(als_avg.regParam, [0.09,0.01,0.5])\\\n",
    "    .build()\n",
    "evaluator_ALS_avg=RegressionEvaluator(metricName=\"rmse\",labelCol=\"Average\",predictionCol=\"ALS_prediction_avg\")\n",
    "cv = CrossValidator(estimator = als_avg,estimatorParamMaps = param_grid,evaluator = evaluator_ALS_avg,numFolds = 3)\n",
    "ALS_model_CV_avg = cv.fit(training_df)\n",
    "ALS_model_avg = ALS_model_CV_avg.bestModel\n",
    "ALS_predictions_avg = ALS_model_avg.transform(test_df)\n",
    "rmse_ALS_avg=evaluator_ALS_avg.evaluate(ALS_predictions_avg)\n",
    "print(\"RMSE considering Average in ALS=\"+str(rmse_ALS_avg))\n",
    "# Print evaluation metrics and model parameters\n",
    "print (\"**Best Model**\")\n",
    "print (\"RMSE = \", rmse_ALS_avg)\n",
    "print (\" Rank: \", ALS_model_avg.rank)\n",
    "print (\" MaxIter: \", ALS_model_avg._java_obj.parent().getMaxIter())\n",
    "print (\" RegParam: \", ALS_model_avg._java_obj.parent().getRegParam())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_ALS_avg=RegressionEvaluator(metricName=\"mae\",labelCol=\"Average\",predictionCol=\"ALS_prediction_avg\")\n",
    "rmse_ALS_avg=evaluator_ALS_avg.evaluate(ALS_predictions_avg)\n",
    "rmse_ALS_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_recs_avg=ALS_model_avg.recommendForAllUsers(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IndexToString\n",
    "from pyspark.ml.feature import StringIndexerModel\n",
    "user_labels = revIDindexer.fit(df_ALS).labels\n",
    "product_labels = asinindexer.fit(df_ALS).labels\n",
    "user_id_to_label = IndexToString(inputCol=\"reviewerID_index\", outputCol=\"reviewerId\", labels=user_labels)\n",
    "n = 5\n",
    "product_labels_ =F.array(*[F.lit(x) for x in product_labels])\n",
    "recommendations = F.array(*[F.struct(product_labels_[F.col(\"recommendations\")[i][\"asin_index\"]].alias(\"asin\"),F.col(\"recommendations\")[i][\"rating\"].alias(\"rating\")) for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_recom_avg = user_id_to_label.transform(user_recs_avg)\n",
    "final_recom_avg = final_recom_avg.withColumn(\"recommendations\",recommendations)\n",
    "final_recom_avg.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item Recommended for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_recom_avg.select('recommendations').filter(final_recom_avg['reviewerID']==revID).show(2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-mynewenv2]",
   "language": "python",
   "name": "conda-env-.conda-mynewenv2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
